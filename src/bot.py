from typing import Dict, List, Optional

from chatgpt_md_converter import telegram_format

import chromadb
from markdownify import markdownify
from ollama import AsyncClient, Options
from huggingface_hub import AsyncInferenceClient

from datetime import datetime
import logging
from aiogram import F, Bot, Dispatcher, html, md
from aiogram.types import Message, LinkPreviewOptions
from aiogram.enums import ParseMode
from aiogram.filters import Command

from db import Answer, User, free_generate, llm_generate
import rag
from settings import Settings

STEP_LIMIT = 4000
FREE_API = "https://openrouter.ai/api/v1/chat/completions"

class MyBot:
    def __init__(self, loop, settings: Settings) -> None:
        self.bot = Bot(settings.bot_token)
        self.model_client = AsyncClient()
        self.free_model_token = settings.free_model_token
        self.inference_client = AsyncInferenceClient(
            provider="hf-inference",
        	api_key=settings.inference_token,
        )
        
        self.loop = loop
        self.users = {}
        
        # Rate limits
        self.client_count = 0
        self.max_client_count = settings.max_client_count
        self.free_uses_count = settings.free_uses_count
        self.uses_span = settings.uses_span
    
    
    async def start_polling(self):
        dp = Dispatcher()
        dp.message.register(self.cmd_start, Command("start"))
        dp.message.register(self.cmd_account, Command("account"))
        dp.message.register(self.cmd_clear, Command("clear"))
        dp.message.register(self.handle_question, F.text)
        await dp.start_polling(self.bot)
    
    
    async def cmd_start(self, message: Message):
        await message.reply("Ð”Ð°, ÑÑ‚Ð°Ñ€Ñ‚. Ð¡Ð¿Ñ€Ð¾ÑÐ¸ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ")
    
    
    async def cmd_account(self, message: Message):
        user = self.get_user(message.from_user.id)
        await message.reply(
            f"Ð—Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð² Ð´ÐµÐ½ÑŒ: {user.uses_count}/{self.free_uses_count}\n"
        )
    
    
    async def cmd_clear(self, message: Message):
        user = self.get_user(message.from_user.id)
        user.dialog.clear()
        await message.reply("ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÑƒÐ´Ð°Ð»ÐµÐ½")
    

    async def handle_question(self, message: Message):
        self.client_count += 1
        try:
            await self.question_inner(message)
        except Exception as e:
            logging.error(f"failed request for user({message.from_user.id}): {e}")
            await message.reply("Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº...")
        self.client_count -= 1
    
    
    async def question_inner(self, message: Message):
        logging.info(f"question by {message.from_user.username}({message.from_user.id})")
        user = self.get_user(message.from_user.id)
        
        # Checking rate limits 
        if user.uses_count >= self.free_uses_count:
            await message.reply("Ð‘ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð¸ÑÑŒ, Ð¶Ð´Ð¸Ñ‚Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð´Ð½Ñ")
            return
          
        if self.is_full():
            await message.reply("Ð’ Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ")
            return

        remaining = self.uses_span - elapsed(user.last_used)
        if remaining > 0:
            await message.reply(f"ÐÐµ Ñ‚Ð°Ðº Ð±Ñ‹ÑÑ‚Ñ€Ð¾, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ ÐµÑ‰Ðµ {remaining:.1f}s")
            return
        
        user.last_used = datetime.now()
        
        temporary = await message.reply("Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ñ€Ð¸Ð½ÑÑ‚, Ð¼Ð¸Ð½ÑƒÑ‚Ñƒ... Ð¸Ð»Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°")
        # Answer question
        answer = await self.chat_with_user(user, message)
        await temporary.delete()

        if answer.text == None:
            await message.reply("Ð”Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ðŸ˜”\n\nÐ‘ÑƒÐ´ÐµÑ‚ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ñ‡ÐµÑ€ÐµÐ· Ð±Ð»Ð¸Ð¶Ð°Ð¹Ñ‰Ð¸Ðµ 24 Ñ‡Ð°ÑÐ°, Ð½Ð°Ð²ÐµÑ€Ð½Ð¾Ðµ ðŸ˜Ž")
        elif answer.text == "":
            temporary = await message.reply("Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸, Ñ‡ÐµÐ¼ Ð¾Ð¶Ð¸Ð´Ð°Ð»Ð¾ÑÑŒ...")
            answer = await self.chat_with_user(user, message)
            if answer.text == "" or answer.text == None:
                await message.reply("Ð‘Ð¾Ð»ÑŒÑˆÐ°Ñ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð° Ð¿Ð¾Ð·Ð¶Ðµ :(")
            await temporary.delete()
        
        # Send answer
        if answer.text != None:
            await self.send_message(message, answer)
            # await message.reply(f"Ð—Ð°Ð½ÑÐ»Ð¾ {elapsed(user.last_used):.1f}s")
        
        # Delete old messages
        while len(user.dialog) >= 8:
            user.dialog = user.dialog[2:]

        # Add new messages
        user.dialog.append(
            {
                "role": "user", 
                "content": message.text
            },
        )
        
        user.dialog.append(
            {
                "role": "assistant", 
                "content": answer.text
            }
        )

    async def send_message(self, message, answer):
        if thinking := answer.thinking:
            if len(thinking) + len(answer.text) > STEP_LIMIT:
                await self.reply_expandable_blockquote(message, thinking)
                await self.reply(message, answer.text)
            else:
                await self.reply(message, html.expandable_blockquote(thinking) + answer.text)
        else:
            await self.reply(message, answer.text)

    async def reply(self, message: Message, text):
        for i in range(0, len(text), STEP_LIMIT):
            chunk = text[i:i + STEP_LIMIT]
            try:
                await message.reply(chunk, parse_mode=ParseMode.HTML, link_preview_options=LinkPreviewOptions(prefer_small_media=True))
            except Exception as e:
                logging.error(f"failed reply with `parse_mode=HTML` for user({message.from_user.id}): {e}")
                await message.reply(chunk)
    
    
    async def reply_expandable_blockquote(self, message, text):
        for i in range(0, len(text), STEP_LIMIT):
            chunk = html.expandable_blockquote(text[i:i + STEP_LIMIT])
            try:
                await message.reply(chunk, parse_mode=ParseMode.HTML)
            except Exception as e:
                logging.error(f"failed reply with `parse_mode=HTML` for user({message.from_user.id}): {e}")
                await message.reply(chunk)
    
    
    async def chat_with_user(self, 
        user: User, 
        message: Message, 
        max_tokens: Optional[int] = 2048
    ) -> Answer:
        logging.info(f"use chat_free")
        
        logging.info("search with rag")
        extra = await self.search_with_rag(message)
        
        user.dialog.extend([
            {
                "role": "user",
                "content": f"RAG SYSTEM: {{{extra}}}. " + self.format_with_system(f" USER: {message.text}"), 
            },
        ])
        
        answer_msg = await message.answer(
            text=md.bold("ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÐ¼ ðŸ“"),
            parse_mode=ParseMode.MARKDOWN,
        )
        
        logging.info("generate answer")
        answer = await llm_generate(
            self.inference_client, 
            self.free_model_token, 
            user.dialog, 
            max_tokens,
        )
        
        user.dialog = user.dialog[:-1]
        await answer_msg.delete()
        return answer
    

    async def search_with_rag(self, message: Message) -> list[str]:
        client = chromadb.Client()
        collection = client.create_collection(name="documents", get_or_create=True)
        data = await rag.search(self.inference_client, self.free_model_token, self.model_client, collection, message)        
        if len(collection.get()["ids"]) > 0:
            collection.delete(collection.get()["ids"])
        return data
    
    
    async def chat_local(
        self,
        messages: List[Dict[str, str]],
        content: str,
        max_tokens: Optional[int],
    ) -> Answer:
        raise RuntimeError("todo")
    
        # * Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð±Ð°Ð·Ñƒ
        client = chromadb.Client()
        collection = client.create_collection(name="documents", get_or_create=True)
        # * Ð˜Ñ‰ÐµÐ¼ 
        extra = await rag.search(self.model_client, collection, content)
        print(extra)
        
        if len(collection.get()["ids"]) > 0:
            collection.delete(collection.get()["ids"])
                
        # Getting answer
        messages.extend([
            {
                "role": "system",
                "content": self.system(),
            },
            {
                "role": "user",
                "content": f"RAG SYSTEM: {{{extra}}}. USER: {content}",
            }
        ])
        
        response = await self.model_client.chat(
            model="bambucha/saiga-llama3:8b",
            messages=messages,
            options=Options(
                num_predict=max_tokens,
            ),
        )
        answer = response.message.content
        # Clean up
        messages = messages[:-2]
        
        # Convert into telegram style
        # chunks = list(answer.split("</think>"))
        # thinking = chunks[0].replace("<think>", "<b>Thinking</b>")
        # thinking = chunks[0].replace("<think>", "<blockquote expandable><b>Thinking</b>") + "</blockquote>"
        # answer = telegram_format(chunks[-1])
        answer = telegram_format(answer)
        
        # async with Translator() as translator:
            # translate = await translator.translate(answer, dest="ru")
            # answer = translate.text
        
        return Answer(None, answer)
    
    def format_with_system(self, content: str) -> str:
        return self.system() + content
    
    def system(self) -> str:
        return (
                "You are the best assistant for searching and checking information, you don't use emojis. "
                "You have up-to-date data thanks to the RAG system."
                # "If the question is complex you first give a short answer in two to five phrases, then write everything down point by point (3-5) and sum it up, use **bold** text for main ideas. Divide text into paragraphs (more is better)"
                # "If the question is easy, answer immediately. Tell at least one phrase. "
                "Use TELEGRAM MARKDOWN for links and other stuff. Be careful in this case, please. "
                "LaTeX not work in telegram, not use LaTeX, please. "
                # "Instead of headings, just use bold text\nExample: ### Top Languages â€‹â€‹â€‹â€‹=> **Top Languages**\n"
                "Please note which sites you are taking data from, if any."
                )
    
    def is_full(self) -> bool:
        return self.client_count == self.max_client_count + 1
    
    
    def get_user(self, id: int) -> User:
        if self.users.get(id) == None:
            self.add_user(id)
        return self.users[id]
    
    
    def add_user(self, id: int):
        self.users[id] = User(
            id=id,
            last_used=datetime.min,
            uses_count=0,
            dialog=[]
        ) 


def elapsed(datetime: datetime) -> float:
    return (datetime.now() - datetime).total_seconds()